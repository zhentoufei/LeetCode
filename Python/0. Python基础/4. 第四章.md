### 1. 如何使用多线程
**实际案例**  
我们通过雅虎网站获取了中国股市某只股票[csv数据文件](http://table.finance.yahoo.com/table.csv?s=000001.sz)，现在要下载多只股票的csv数据，并将其转换为xml文件
如何使用多线程来跳高下载处理的效率？  

**解决方案**  
使用标准库threading.Thread创建线程，在每一个线程中下载并转换已知股票数据
```python
# coding:utf-8
# 简单的线程使用
import csv
from xml.etree.ElementTree import Element, ElementTree
import requests
from StringIO import StringIO


# 美化xml的输出
def pretty(e, level=0):
    if len(e) > 0:
        e.text = '\n' + '\t' * (level + 1)
        for child in e:
            pretty(child, level + 1)
        child.tail = child.tail[:-1]
    e.tail = '\n' + '\t' * level


def download(url):
    response = requests.get(url, timeout=3)
    if response.ok:
        return StringIO(response.content)


def csv2xml(scsv, fxml):
    reader = csv.reader(scsv)
    headers = reader.next()
    headers = map(lambda h: h.repace(' ', ''), headers)
    root = Element('Data')
    for row in reader:
        eRow = Element('Row')
        root.append(eRow)
        for tag, text in zip(headers, row):
            e = Element(tag)
            e.text = text
            eRow.append(e)

    pretty(root)
    et = ElementTree(root)
    et.write(fxml)


def handle(sid):
    url = 'http://table.finance.yahoo.com/table.csv?s=000001.sz'
    url %= str(sid).rjust(6, '0')
    rf = download(url)
    if rf is None:
        return

    print 'Convert to xml ...(%d)' % sid
    fname = str(sid).rjust(6, '0') + '.xml'
    with open(fname, 'wb') as wf:
        csv2xml(rf, wf)

class MyThread(Thread):
    def run(self):
        

from threading import Thread
if __name__ == '__main__':
    t = Thread(target=handle, args=(1,))
    t.start()
    print 'main thread...'
```
```python
# coding:utf-8
# 将线程写成一个类，封装起来
import csv
from xml.etree.ElementTree import Element, ElementTree
import requests
from StringIO import StringIO

from threading import Thread


# 美化xml的输出
def pretty(e, level=0):
    if len(e) > 0:
        e.text = '\n' + '\t' * (level + 1)
        for child in e:
            pretty(child, level + 1)
        child.tail = child.tail[:-1]
    e.tail = '\n' + '\t' * level


def download(url):
    response = requests.get(url, timeout=3)
    if response.ok:
        return StringIO(response.content)


def csv2xml(scsv, fxml):
    reader = csv.reader(scsv)
    headers = reader.next()
    headers = map(lambda h: h.repace(' ', ''), headers)
    root = Element('Data')
    for row in reader:
        eRow = Element('Row')
        root.append(eRow)
        for tag, text in zip(headers, row):
            e = Element(tag)
            e.text = text
            eRow.append(e)

    pretty(root)
    et = ElementTree(root)
    et.write(fxml)


def handle(sid):
    url = 'http://table.finance.yahoo.com/table.csv?s=000001.sz'
    url %= str(sid).rjust(6, '0')
    rf = download(url)
    if rf is None:
        return

    print 'Convert to xml ...(%d)' % sid
    fname = str(sid).rjust(6, '0') + '.xml'
    with open(fname, 'wb') as wf:
        csv2xml(rf, wf)


class MyThread(Thread):
    def __init__(self, sid):
        Thread.__init__(self)
        self.sid = sid

    def run(self):
        handle(self.sid)
        pass


if __name__ == '__main__':
    t = MyThread(1)
    t.start()
    t.join() # 保证子线程运行完毕再退出主线程
    
    
    
    # 多个线程的等待退出
    threads = []
    for i in xrange(1, 11):
        t = MyThread(i)
        threads.append(t)
        t.start()

    for t in threads:
        t.join()  # 让等待每个子线程的退出
```
**注意**：python中的线程不适合处理cpu密集型的操作，因为有个全局解释器锁，导致每个时刻只有一个线程被一个python解释器执行，只适合处理IO型的操作
### 2. 如何进行线程间的通信
**实际案例**  
如1中的案例
由于全局解释器锁的存在，多线程进行CPU密集型操作并不能提高执行效率，我们修改程序架构：
1. 使用多个DownloadThread线程进行下载(I/O操作)
2. 使用一个ConvertThread线程进行转换(CPU密集型操作)
3. 下载线程把下载数据安全地传递给转换线程   

**解决方案**  
使用标准库中的Queue.Queue，它是一个线程安全的队列，Download线程把下载数据放入队列，Convert线程从队列里提取数据	
```python
# coding:utf-8

import csv
from xml.etree.ElementTree import Element, ElementTree
import requests
from StringIO import StringIO

from threading import Thread
from Queue import Queue


# 美化xml的输出
def pretty(e, level=0):
    if len(e) > 0:
        e.text = '\n' + '\t' * (level + 1)
        for child in e:
            pretty(child, level + 1)
        child.tail = child.tail[:-1]
    e.tail = '\n' + '\t' * level


class DownloadThread(Thread):
    def __init__(self, sid, queue):
        Thread.__init__(self)
        self.sid = sid
        self.url = 'http://table.finance.yahoo.com/table.csv?s=000001.sz'
        self.url %= str(sid).rjust(6, '0')
        self.queue = queue

    def download(self, url):
        response = requests.get(url, timeout=3)
        if response.ok:
            return StringIO(response.content)

    def run(self):
        # 1.下载
        data = self.download(self.url)
        # 2. sid, data
        # lock
        self.queue.put((self.sid, data))


class ConverThread(Thread):
    def __init__(self, queue):
        Thread.__init__(self)
        self.queue = queue

    def csv2xml(self, scsv, fxml):
        reader = csv.reader(scsv)
        headers = reader.next()
        headers = map(lambda h: h.repace(' ', ''), headers)
        root = Element('Data')
        for row in reader:
            eRow = Element('Row')
            root.append(eRow)
            for tag, text in zip(headers, row):
                e = Element(tag)
                e.text = text
                eRow.append(e)

        pretty(root)
        et = ElementTree(root)
        et.write(fxml)

    def run(self):
        while True:
            # sid, data
            sid, data = self.queue.get()
            if sid == -1:
                break
            if data:
                fname = str(self.sid).rjust(6, '0') + '.xml'
                with open(fname, 'wb') as wf:
                    self.csv2xml(self.data, wf)


if __name__ == '__main__':
    q = Queue()
    dThreads = [DownloadThread(i, q) for i in xrange(1, 11)]
    cThread = ConverThread(q)
    for t in dThreads:
        t.start()
    cThread.start()
    for t in dThreads:
        t.join()
    q.put(-1, None)
```
### 3. 进行线程间的时间通知？
**实际案例**  
如1中的案例
*额外需求*  
实现一个线程，将转换出的xml文件压缩打包，比如转换线程没生产出100个xml文件，就通知打包线程将他们打包成一个xxx.tgz文件，并删除xml文件，打包完成过后，打包线程反过来通知转换线程，转换线程继续转换  
**解决方案**  
线程间的事件通知，可以使用标准库中的Thread.Event:
1. 等待事件一端调用wait，等待事件
2. 通知事件一端调用set，通知事件  
```python
# coding:utf-8

import csv
from xml.etree.ElementTree import Element, ElementTree
import requests
from StringIO import StringIO

from threading import Thread, Event
from Queue import Queue
import tarfile
import os


# 美化xml的输出
def pretty(e, level=0):
    if len(e) > 0:
        e.text = '\n' + '\t' * (level + 1)
        for child in e:
            pretty(child, level + 1)
        child.tail = child.tail[:-1]
    e.tail = '\n' + '\t' * level


class DownloadThread(Thread):
    def __init__(self, sid, queue):
        Thread.__init__(self)
        self.sid = sid
        self.url = 'http://table.finance.yahoo.com/table.csv?s=000001.sz'
        self.url %= str(sid).rjust(6, '0')
        self.queue = queue

    def download(self, url):
        response = requests.get(url, timeout=3)
        if response.ok:
            return StringIO(response.content)

    def run(self):
        # 1.下载
        data = self.download(self.url)
        # 2. sid, data
        # lock
        self.queue.put((self.sid, data))


class ConverThread(Thread):
    def __init__(self, queue, cEvent, tEvent):
        Thread.__init__(self)
        self.queue = queue
        self.cEvent = cEvent
        self.tEvent = tEvent

    def csv2xml(self, scsv, fxml):
        reader = csv.reader(scsv)
        headers = reader.next()
        headers = map(lambda h: h.repace(' ', ''), headers)
        root = Element('Data')
        for row in reader:
            eRow = Element('Row')
            root.append(eRow)
            for tag, text in zip(headers, row):
                e = Element(tag)
                e.text = text
                eRow.append(e)

        pretty(root)
        et = ElementTree(root)
        et.write(fxml)

    def run(self):
        count = 0
        while True:
            # sid, data
            sid, data = self.queue.get()
            if sid == -1:
                self.cEvent.set()
                self.tEvent.wait()
                break
            if data:
                fname = str(self.sid).rjust(6, '0') + '.xml'
                with open(fname, 'wb') as wf:
                    self.csv2xml(self.data, wf)
                count += 1
                if count == 5:
                    self.cEvent.set()
                    self.tEvent.wait()
                    self.tEvent.clear()
                    count = 0


# 设置成守护线程，在其他线程没有的时候，这个线程也就没了
class TarThread(Thread):
    def __init__(self, cEvent, tEvent):
        Thread.__init__(self)
        self.count = 0
        self.cEvent = cEvent
        self.tEvent = tEvent
        self.setDaemon(True)  # 设置守护线程

    def tarXml(self):
        self.count += 1
        tfname = '%d.tgz' % self.count
        tf = tarfile.open(tfname, 'w:gz')
        for fname in os.listdir('.'):
            tf.add(fname)
            os.remove(fname)
        tf.close()

        if not tf.members:
            os.remove(tfname)

    def run(self):
        while True:
            self.cEvent.wait()
            self.tarXml()
            self.cEvent.clear()

            self.tEvent.set()


if __name__ == '__main__':
    q = Queue()
    dThreads = [DownloadThread(i, q) for i in xrange(1, 11)]

    cEvent = Event()
    tEvent = Event()

    cThread = ConverThread(q, cEvent, tEvent)
    tThread = TarThread(cEvent, tEvent)
    tThread.start()
    for t in dThreads:
        t.start()
    cThread.start()
    for t in dThreads:
        t.join()
    q.put(-1, None)
```
### 2. 线程池？
**实际案例**  
我们实现了一个多线程web视频监控服务器，我们要对请求连接数做限制，以防止恶意用户发起大量连接而导致服务器创建大量想成，最终因资源耗尽而瘫痪
可以使用线程池替代原来的每次请求创建线程  
**解决方案**  
使用标准库中concurrent.futures下的ThreadPoolExecutor对象的submit和map方法可以来启动线程池中线程执行任务

```python
# coding:utf-8
# 先来一个小🌰
from concurrent.futures import ThreadPoolExecutor
import time

executor = ThreadPoolExecutor(2)  # 最多两个线程


def f(a, b):
    print('f', a, b)
    time.sleep(2)
    return a ** b


print executor.submit(f, 2, 3)

future = executor.submit(f, 2, 4)
print future.result()  # 获得结果

# 计算多个函数 2**5, 3**6, 4**7
print executor.map(f, [2, 3, 4], [5, 6, 7])

```
```python
# coding:utf-8

import os, cv2,  struct, threading
from http.server import HTTPServer, BaseHTTPRequestHandler
from socketserver import TCPServer, ThreadingTCPServer
from threading import Thread, RLock
from select import select
from concurrent.futures import ThreadPoolExecutor


class JpegStreamer(Thread):
    def __init__(self, camera):
        Thread.__init__(self)
        self.cap = cv2.VideoCapture(camera)
        self.lock = RLock()
        self.pipes = {}

    def register(self):
        pr, pw = os.pipe()
        self.lock.acquire()
        self.pipes[pr] = pw
        self.lock.release()
        return pr

    def unregister(self, pr):
        self.lock.acquire()
        pw = self.pipes.pop(pr)
        self.lock.release()
        os.close(pr)
        os.close(pw)

    def capture(self):
        cap = self.cap
        while cap.isOpened():
            ret, frame = cap.read()
            if ret:
                # ret, data = cv2.imencode('.jpg', frame)
                ret, data = cv2.imencode('.jpg', frame, (cv2.IMWRITE_JPEG_QUALITY, 40))
                yield data.tostring()

    def send(self, frame):
        n = struct.pack('l', len(frame))
        self.lock.acquire()
        if len(self.pipes):
            _, pipes, _ = select([], iter(self.pipes.values()), [], 1)
            for pipe in pipes:
                os.write(pipe, n)
                os.write(pipe, frame)
        self.lock.release()

    def run(self):
        for frame in self.capture():
            self.send(frame)


class JpegRetriever(object):
    def __init__(self, streamer):
        self.streamer = streamer
        self.local = threading.local()

    def retrieve(self):
        while True:
            ns = os.read(self.local.pipe, 8)
            n = struct.unpack('l', ns)[0]
            data = os.read(self.local.pipe, n)
            yield data

    def __enter__(self):
        if hasattr(self.local, 'pipe'):
            raise RuntimeError()

        self.local.pipe = streamer.register()
        return self.retrieve()

    def __exit__(self, *args):
        self.streamer.unregister(self.local.pipe)
        del self.local.pipe
        return True


class Handler(BaseHTTPRequestHandler):
    retriever = None

    @staticmethod
    def setJpegRetriever(retriever):
        Handler.retriever = retriever

    def do_GET(self):
        if self.retriever is None:
            raise RuntimeError('no retriver')

        if self.path != '/':
            return

        self.send_response(200)
        self.send_header('Content-type', 'multipart/x-mixed-replace;boundary=abcde')
        self.end_headers()

        with self.retriever as frames:
            for frame in frames:
                self.send_frame(frame)

    def send_frame(self, frame):
        s = '--abcde\r\n'
        s += 'Content-Type: image/jpeg\r\n'
        s += 'Content-Length: %s\r\n\r\n' % len(frame)
        self.wfile.write(s.encode('ascii'))
        self.wfile.write(frame)

# 重写了ThreadingTCPServer的方法
def ThreadingPoolTCPServer(ThreadingTCPServer):
    def __init__(self, server_address, RequestHandlerClass, bing_and_activate=True,
                 max_thread_num = 100):
        super().__init__(server_address, RequestHandlerClass, bing_and_activate)
        self.executor = ThreadPoolExecutor(max_thread_num)

    def process_request(self, request, client_address):
        self.executor.submit(self.process_request_thread, request, client_address)

if __name__ == '__main__':
    streamer = JpegStreamer(0)
    streamer.start()

    retriever = JpegRetriever(streamer)
    Handler.setJpegRetriever(retriever)

    print('Start server...')
    httpd = ThreadingPoolTCPServer(('', 9000), Handler, max_thread_num = 3)
    httpd.serve_forever()

```
### 3. 如何使用多进程？
**实际案例**  
由于python中全局解释器(GIL)的存在，在任意时刻只允许一个线程在解释其中运行，因此python的多线程不适合处理CPU密集型的任务

想要处理cpu密集型的任务可以使用多进程模型
注：多个进程之间的变量是不同的，当主进程的变量转到另外一个进程中，在新的进程中修改了该变量的值，但是在主进程中产看的时候还是原来的变量值
```python
# coding:utf-8
from multiprocessing import Process, Queue, freeze_support
def f(q):
    print 'start'
    print q.get()
    print 'end'

if __name__ == '__main__':
    freeze_support()

    q = Queue()
    q.put(1)
    print q.get()

    Process(target=f, args=(q,)).start()
    q.put(2)
    # 输出如下
    # 1
    # start
    # 2
    # end
```
Pipe的用法
```python
# coding:utf-8
from multiprocessing import Pipe, Process
def f(c):
    c.send(c.recv() * 2)

if __name__ == '__main__':
    c1, c2 = Pipe()
    Process(target=f, args=(c2, )).start()
    c1.send('asdd')
    print c1.recv()
    # 输出 asddasdd
```
```python
# coding:utf-8
# CPU密集型的任务
from multiprocessing import Pipe, Process
from threading import Thread


def isArmstrong(n):
    a, t = [], n
    while t > 0:
        a.append(t % 10)
        t /= 10
    k = len(a)
    return sum(x ** k for x in a) == n


def findAemstrong(a, b):
    print a, b
    res = [k for k in xrange(a, b) if isArmstrong(k)]
    print '%s ~ %s: %s' % (a, b, res)


def findByThread(*argslist):
    workers = []
    for args in argslist:
        worker = Thread(target=findAemstrong, args=args)
        workers.append(worker)
        worker.start()

    for work in workers:
        worker.join()


def findByProcess(*argslist):
    workers = []
    for args in argslist:
        worker = Process(target=findAemstrong, args=args)
        workers.append(worker)
        worker.start()

    for work in workers:
        worker.join()


if __name__=='__main__':
    import time
    start = time.time()
    findByProcess((20000000, 25000000), (25000000, 30000000))
    # findByThread((20000000, 25000000), (25000000, 30000000))
    print time.time()-start
```